---
id: diskann-explained.md
title: DiskANN объясняется
author: Stefan Webb
date: 2025-05-20T00:00:00.000Z
desc: >-
  Узнайте, как DiskANN обеспечивает миллиардные масштабы векторного поиска с
  помощью твердотельных накопителей, балансируя между низким потреблением
  памяти, высокой точностью и масштабируемой производительностью.
cover: assets.zilliz.com/Disk_ANN_Explained_35db4b3ef1.png
tag: Engineering
recommend: false
publishToMedium: true
tags: 'Milvus, vector database, vector search'
meta_keywords: >-
  Milvus, DiskANN, vector similarity search, indexing, Vamana algorithm, disk
  vector search
meta_title: DiskANN Explained
origin: 'https://milvus.io/blog/diskann-explained.md'
---
<h2 id="What-is-DiskANN" class="common-anchor-header">Что такое DiskANN?<button data-href="#What-is-DiskANN" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p><a href="https://github.com/microsoft/DiskANN">DiskANN</a> представляет собой подход, меняющий парадигму <a href="https://zilliz.com/learn/vector-similarity-search">поиска векторного сходства</a>. До этого большинство типов векторных индексов, таких как HNSW, в значительной степени зависели от оперативной памяти, чтобы добиться низкой задержки и высокого уровня запоминания. Хотя этот подход эффективен для наборов данных умеренного размера, он становится непомерно дорогим и менее масштабируемым по мере роста объемов данных. DiskANN предлагает экономически эффективную альтернативу, используя для хранения индекса твердотельные накопители, что значительно снижает требования к памяти.</p>
<p>DiskANN использует плоскую структуру графа, оптимизированную для доступа к диску, что позволяет ей обрабатывать миллиардные массивы данных с меньшим объемом памяти, чем требуется методам in-memory. Например, DiskANN может индексировать до миллиарда векторов, достигая при этом 95 % точности поиска с задержками в 5 мс, в то время как алгоритмы на базе оперативной памяти достигают аналогичной производительности при 100-200 миллионах точек.</p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Vector_indexing_and_search_workflow_with_Disk_ANN_41cdf33652.png" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Рисунок 1: Рабочий процесс индексирования и поиска векторов с помощью DiskANN</em></p>
<p>Несмотря на то, что DiskANN может иметь несколько большую задержку по сравнению с подходами на базе оперативной памяти, компромисс часто оказывается приемлемым, учитывая значительную экономию средств и преимущества масштабируемости. DiskANN особенно подходит для приложений, требующих крупномасштабного векторного поиска на аппаратном обеспечении.</p>
<p>В этой статье мы расскажем о том, как DiskANN использует SSD в дополнение к оперативной памяти и сокращает количество дорогостоящих операций чтения с SSD.</p>
<h2 id="How-Does-DiskANN-Work" class="common-anchor-header">Как работает DiskANN?<button data-href="#How-Does-DiskANN-Work" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>DiskANN - это метод векторного поиска на основе графа, относящийся к тому же семейству методов, что и HNSW. Сначала мы строим граф поиска, в котором узлы соответствуют векторам (или группам векторов), а ребра обозначают, что пара векторов "относительно близка" в некотором смысле. Типичный поиск случайным образом выбирает "начальный узел" и переходит к его соседу, ближайшему к запросу, повторяя жадным образом, пока не будет достигнут локальный минимум.</p>
<p>Системы индексирования на основе графов различаются в первую очередь тем, как они строят граф поиска и выполняют поиск. В этом разделе мы подробно рассмотрим инновации DiskANN на этих этапах и то, как они обеспечивают производительность при низких задержках и малом объеме памяти. (Краткое описание см. на рисунке выше).</p>
<h3 id="An-Overview" class="common-anchor-header">Обзор</h3><p>Мы предполагаем, что пользователь сгенерировал набор векторных вкраплений документов. Первым шагом является кластеризация вкраплений. Граф поиска для каждого кластера строится отдельно с помощью алгоритма Vamana (описанного в следующем разделе), а результаты объединяются в один граф. <em>Стратегия "разделяй и властвуй" для создания окончательного графа поиска значительно сокращает потребление памяти, не слишком влияя на задержку поиска и запоминание.</em></p>
<p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/How_Disk_ANN_stores_vector_index_across_RAM_and_SSD_d6564b087f.jpg" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Рисунок 2: Как DiskANN хранит векторный индекс в оперативной памяти и на твердотельном накопителе</em></p>
<p>После создания глобального графа поиска он хранится на SSD вместе с векторными вкраплениями полной точности. Основная проблема заключается в том, чтобы завершить поиск за ограниченное количество чтений с SSD, поскольку доступ к SSD является дорогим по сравнению с доступом к RAM. Поэтому для ограничения количества считываний используется несколько хитроумных приемов:</p>
<p>Во-первых, алгоритм Vamana поощряет более короткие пути между близкими узлами, ограничивая максимальное количество соседей узла. Во-вторых, для хранения вкраплений каждого узла и его соседей используется структура данных фиксированного размера (см. рисунок выше). Это означает, что мы можем обращаться к метаданным узла, просто умножая размер структуры данных на индекс узла и используя его в качестве смещения, одновременно получая встраивание узла. В-третьих, благодаря тому, как работают SSD, мы можем получить несколько узлов за один запрос на чтение - в нашем случае соседние узлы - что еще больше сокращает количество запросов на чтение.</p>
<p>Отдельно мы сжимаем вкрапления с помощью квантования произведения и храним их в оперативной памяти. Таким образом, мы можем поместить миллиардные наборы векторных данных в память, которая может быть использована на одной машине для быстрого вычисления <em>приблизительного сходства векторов</em> без чтения с диска. Это дает рекомендации по сокращению числа соседних узлов для следующего доступа на SSD. Важно, однако, что решения о поиске принимаются с использованием <em>точных векторных сходств</em>, а полные вкрапления извлекаются с твердотельного диска, что обеспечивает более высокий отзыв. Подчеркнем, что существует начальная фаза поиска с использованием квантованных вкраплений в памяти и последующий поиск на меньшем подмножестве, считываемом с SSD.</p>
<p>В этом описании мы обошли вниманием два важных, хотя и сложных этапа: построение графа и поиск в нем - два этапа, обозначенные красными рамками выше. Давайте рассмотрим каждый из них по очереди.</p>
<h3 id="Vamana-Graph-Construction" class="common-anchor-header">Построение графа "Вамана"</h3><p>
  <span class="img-wrapper">
    <img translate="no" src="https://assets.zilliz.com/Vamana_Graph_Construction_ecb4dab839.jpg" alt="" class="doc-image" id="" />
    <span></span>
  </span>
</p>
<p><em>Рисунок: Построение графа "Вамана"</em></p>
<p>Авторы DiskANN разработали новый метод построения графа поиска, который они назвали алгоритмом Vamana. Он инициализирует граф поиска, добавляя случайным образом O(N) ребер. В результате получается "хорошо связанный" граф, хотя и без каких-либо гарантий сходимости жадного поиска. Затем он обрезает и пересоединяет ребра интеллектуальным способом, чтобы обеспечить достаточное количество дальних связей (см. рисунок выше). Позвольте нам рассказать об этом подробнее:</p>
<h4 id="Initialization" class="common-anchor-header">Инициализация</h4><p>Граф поиска инициализируется случайным направленным графом, в котором каждая вершина имеет R внешних соседей. Мы также вычисляем медоид графа, то есть точку, которая имеет минимальное среднее расстояние до всех остальных точек. Можно считать, что это аналог центроида, который является членом множества узлов.</p>
<h4 id="Search-for-Candidates" class="common-anchor-header">Поиск кандидатов</h4><p>После инициализации мы перебираем узлы, выполняя на каждом шаге как добавление, так и удаление ребер. Сначала мы запускаем алгоритм поиска на выбранном узле p, чтобы сформировать список кандидатов. Алгоритм поиска начинает с медоида и жадно перемещается все ближе и ближе к выбранному узлу, добавляя на каждом шаге внешних соседей ближайшего узла, найденного до сих пор. Возвращается список из L найденных узлов, ближайших к p. (Если вы не знакомы с этим понятием, то медоид графа - это точка, имеющая минимальное среднее расстояние до всех остальных точек и выступающая в качестве аналога центроида для графов).</p>
<h4 id="Pruning-and-Adding-Edges" class="common-anchor-header">Обрезка и добавление ребер</h4><p>Соседи-кандидаты узла сортируются по расстоянию, и для каждого кандидата алгоритм проверяет, не находится ли он "слишком близко" по направлению к уже выбранному соседу. Если да, то он обрезается. Это способствует угловому разнообразию среди соседей, что эмпирически приводит к улучшению навигационных свойств. На практике это означает, что поиск, начинающийся со случайного узла, может быстрее достичь любого целевого узла, исследуя разреженный набор дальних и локальных связей.</p>
<p>После обрезки ребер добавляются ребра вдоль жадного пути поиска к p. Выполняется два прохода обрезки, варьируя порог расстояния для обрезки таким образом, чтобы во время второго прохода добавлялись долгосрочные ребра.</p>
<h2 id="What’s-Next" class="common-anchor-header">Что дальше?<button data-href="#What’s-Next" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><p>В последующих работах на основе DiskANN были сделаны дополнительные улучшения. Один из примечательных примеров, известный как <a href="https://arxiv.org/abs/2105.09613">FreshDiskANN</a>, модифицирует метод, позволяя легко обновлять индекс после его создания. Этот поисковый индекс, обеспечивающий превосходный компромисс между критериями производительности, доступен в векторной базе данных <a href="https://milvus.io/docs/overview.md">Milvus</a> как тип индекса <code translate="no">DISKANN</code>.</p>
<pre><code translate="no" class="language-python"><span class="hljs-comment"># Prepare index parameters</span>
index_params = client.prepare_index_params()

<span class="hljs-comment"># Add DiskANN index</span>
index_params.add_index(
    field_name=<span class="hljs-string">&quot;vector&quot;</span>,
    index_type=<span class="hljs-string">&quot;DISKANN&quot;</span>,
    metric_type=<span class="hljs-string">&quot;COSINE&quot;</span>
)

<span class="hljs-comment"># Create collection with index</span>
client.create_collection(
    collection_name=<span class="hljs-string">&quot;diskann_collection&quot;</span>,
    schema=schema,
    index_params=index_params
)
<button class="copy-code-btn"></button></code></pre>
<p>Вы можете даже настраивать параметры DiskANN, такие как <code translate="no">MaxDegree</code> и <code translate="no">BeamWidthRatio</code>: подробнее см. на <a href="https://milvus.io/docs/disk_index.md#On-disk-Index">странице документации</a>.</p>
<h2 id="Resources" class="common-anchor-header">Ресурсы<button data-href="#Resources" class="anchor-icon" translate="no">
      <svg translate="no"
        aria-hidden="true"
        focusable="false"
        height="20"
        version="1.1"
        viewBox="0 0 16 16"
        width="16"
      >
        <path
          fill="#0092E4"
          fill-rule="evenodd"
          d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"
        ></path>
      </svg>
    </button></h2><ul>
<li><p><a href="https://milvus.io/docs/disk_index.md#On-disk-Index">Документация Milvus по использованию DiskANN</a></p></li>
<li><p><a href="https://suhasjs.github.io/files/diskann_neurips19.pdf">"DiskANN: быстрый точный поиск ближайших соседей по миллиардным точкам на одном узле"</a></p></li>
<li><p><a href="https://arxiv.org/abs/2105.09613">"FreshDiskANN: быстрый и точный индекс ANN на основе графа для потокового поиска сходства"</a></p></li>
</ul>
